{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2f9ba3",
   "metadata": {},
   "source": [
    "# KoBart - Translation (한->영)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e5048",
   "metadata": {},
   "source": [
    "## 프로젝트 목적\n",
    "\n",
    "* 한글을 영어로 번역\n",
    "* 추후에 다른 언어도 번역\n",
    "* 임베디드를 이용한 언어번역 인공지능 상품을 완성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6a30c",
   "metadata": {},
   "source": [
    "## 프로젝트 내용\n",
    "\n",
    "* KoBart - Translation 을 이용하여 음성을 넣고 변화 시키는 것 까지 하려고 하였으나, 학습하는데 시간이 오래걸리고 오류를 잡는데 오랜 시간을 사용하여 음성을 넣는데까지는 못했고 오류를 잡아서 수정을 하였고, jupyter Notebook을 이용하여 사용할 수 있게 만들었다\n",
    "\n",
    "* infer.py의 파일을 수정하여 연속적으로 반복되는 부분을 없도록 수정하였다.\n",
    "* data 파일을 기존은 tsv를 사용하였는데 csv로 수정하였다.\n",
    "* 가상환경이 업데이트 된 지 좀 오래되서 그 부분도 requirments.txt를 이용하여 변경 또는 jupyter Notebook을 통하여 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb1df1a",
   "metadata": {},
   "source": [
    "# 필요한 파일 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d85216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'NLP-pro'...\n",
      "remote: Enumerating objects: 22, done.\u001b[K\n",
      "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
      "remote: Total 22 (delta 2), reused 21 (delta 1), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (22/22), 5.02 MiB | 5.30 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jaegwang-shin/NLP-pro.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c8089",
   "metadata": {},
   "source": [
    "# KoBart 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7dd5a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kobart\n",
      "  Cloning https://github.com/SKT-AI/KoBART to /tmp/pip-install-j358f6q6/kobart_cd2e365dfdb44e56be79d6d9b1d9cf84\n",
      "  Running command git clone -q https://github.com/SKT-AI/KoBART /tmp/pip-install-j358f6q6/kobart_cd2e365dfdb44e56be79d6d9b1d9cf84\n",
      "  Resolved https://github.com/SKT-AI/KoBART to commit 30c5eb7b593828d6ec2d767eeedb2f2ed02c5c2a\n",
      "Requirement already satisfied: boto3 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from kobart) (1.24.0)\n",
      "Requirement already satisfied: pandas in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from kobart) (1.4.2)\n",
      "Collecting pytorch-lightning==1.2.1\n",
      "  Using cached pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
      "Requirement already satisfied: torch==1.7.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from kobart) (1.7.1+cu110)\n",
      "Collecting transformers==4.3.3\n",
      "  Using cached transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pytorch-lightning==1.2.1->kobart) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pytorch-lightning==1.2.1->kobart) (1.22.4)\n",
      "Collecting PyYAML!=5.4.*,>=5.1\n",
      "  Using cached PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pytorch-lightning==1.2.1->kobart) (4.64.0)\n",
      "Requirement already satisfied: fsspec[http]>=0.8.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pytorch-lightning==1.2.1->kobart) (2022.5.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pytorch-lightning==1.2.1->kobart) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from torch==1.7.1->kobart) (4.2.0)\n",
      "Requirement already satisfied: packaging in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.3.3->kobart) (21.3)\n",
      "Requirement already satisfied: filelock in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.3.3->kobart) (3.7.1)\n",
      "Requirement already satisfied: sacremoses in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.3.3->kobart) (0.0.53)\n",
      "Requirement already satisfied: requests in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.3.3->kobart) (2.27.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.3.3->kobart) (2022.4.24)\n",
      "Requirement already satisfied: aiohttp in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (3.8.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (3.20.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (1.46.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (2.1.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (2.6.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (3.3.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (61.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (0.6.1)\n",
      "Requirement already satisfied: six in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (5.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from requests->transformers==4.3.3->kobart) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from requests->transformers==4.3.3->kobart) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from requests->transformers==4.3.3->kobart) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from requests->transformers==4.3.3->kobart) (2022.5.18.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (1.7.2)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from boto3->kobart) (1.27.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from boto3->kobart) (1.0.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from boto3->kobart) (0.6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.0->boto3->kobart) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from packaging->transformers==4.3.3->kobart) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pandas->kobart) (2022.1)\n",
      "Requirement already satisfied: joblib in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from sacremoses->transformers==4.3.3->kobart) (1.1.0)\n",
      "Requirement already satisfied: click in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from sacremoses->transformers==4.3.3->kobart) (8.0.4)\n",
      "Installing collected packages: tokenizers, PyYAML, transformers, pytorch-lightning\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.9.4\n",
      "    Uninstalling tokenizers-0.9.4:\n",
      "      Successfully uninstalled tokenizers-0.9.4\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.0.0\n",
      "    Uninstalling transformers-4.0.0:\n",
      "      Successfully uninstalled transformers-4.0.0\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.1.0\n",
      "    Uninstalling pytorch-lightning-1.1.0:\n",
      "      Successfully uninstalled pytorch-lightning-1.1.0\n",
      "Successfully installed PyYAML-6.0 pytorch-lightning-1.2.1 tokenizers-0.10.3 transformers-4.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/SKT-AI/KoBART#egg=kobart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36885a8",
   "metadata": {},
   "source": [
    "# 필요한 폴더 생성\n",
    "\n",
    "* pytorch_model.bin과 config.json을 translation_binary 폴더에 넣어주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "272f7a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dilab05/work_directory/신재광/NLP-pro\n"
     ]
    }
   ],
   "source": [
    "%cd NLP-pro\n",
    "%mkdir kobart_translation\n",
    "%mkdir translation_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0624a",
   "metadata": {},
   "source": [
    "# GPU 할당하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a4a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1170426",
   "metadata": {},
   "source": [
    "# requirments로 필요한 환경 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea4f4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.4.2)\n",
      "Collecting torch==1.7.0\n",
      "  Using cached torch-1.7.0-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)\n",
      "Collecting transformers==4.0.0\n",
      "  Using cached transformers-4.0.0-py3-none-any.whl (1.4 MB)\n",
      "Collecting pytorch-lightning==1.1.0\n",
      "  Using cached pytorch_lightning-1.1.0-py3-none-any.whl (665 kB)\n",
      "Requirement already satisfied: streamlit in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.10.0)\n",
      "Requirement already satisfied: click==8.0.4 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (8.0.4)\n",
      "Collecting pyyaml==5.4.1\n",
      "  Using cached PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "Requirement already satisfied: dataclasses in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from torch==1.7.0->-r requirements.txt (line 2)) (0.6)\n",
      "Requirement already satisfied: typing-extensions in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from torch==1.7.0->-r requirements.txt (line 2)) (4.2.0)\n",
      "Requirement already satisfied: numpy in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from torch==1.7.0->-r requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: future in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from torch==1.7.0->-r requirements.txt (line 2)) (0.18.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.0.0->-r requirements.txt (line 3)) (4.64.0)\n",
      "Requirement already satisfied: sacremoses in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.0.0->-r requirements.txt (line 3)) (0.0.53)\n",
      "Requirement already satisfied: filelock in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.0.0->-r requirements.txt (line 3)) (3.7.1)\n",
      "Requirement already satisfied: packaging in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.0.0->-r requirements.txt (line 3)) (21.3)\n",
      "Requirement already satisfied: requests in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.0.0->-r requirements.txt (line 3)) (2.27.1)\n",
      "Collecting tokenizers==0.9.4\n",
      "  Using cached tokenizers-0.9.4-cp38-cp38-manylinux2010_x86_64.whl (2.9 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from transformers==4.0.0->-r requirements.txt (line 3)) (2022.4.24)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (2.9.0)\n",
      "Requirement already satisfied: fsspec>=0.8.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (2022.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2022.1)\n",
      "Requirement already satisfied: watchdog in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (2.1.8)\n",
      "Requirement already satisfied: semver in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (2.13.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (4.11.4)\n",
      "Requirement already satisfied: attrs in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (21.4.0)\n",
      "Requirement already satisfied: validators in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (3.20.1)\n",
      "Requirement already satisfied: tornado>=5.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (6.1)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (0.7.1)\n",
      "Requirement already satisfied: cachetools>=4.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (5.1.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (9.1.1)\n",
      "Requirement already satisfied: blinker in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (1.4)\n",
      "Requirement already satisfied: pympler>=0.9 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: altair>=3.2.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (4.2.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (3.1.27)\n",
      "Requirement already satisfied: tzlocal in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (4.2)\n",
      "Requirement already satisfied: rich in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (12.4.4)\n",
      "Requirement already satisfied: pyarrow in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (8.0.0)\n",
      "Requirement already satisfied: toml in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from streamlit->-r requirements.txt (line 5)) (0.10.2)\n",
      "Requirement already satisfied: toolz in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 5)) (0.11.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 5)) (4.5.1)\n",
      "Requirement already satisfied: jinja2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: entrypoints in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 5)) (0.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from gitpython!=3.1.19->streamlit->-r requirements.txt (line 5)) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit->-r requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from importlib-metadata>=1.4->streamlit->-r requirements.txt (line 5)) (3.8.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->-r requirements.txt (line 5)) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->-r requirements.txt (line 5)) (5.7.1)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (5.2.2.post1)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (7.7.0)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (6.13.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (7.3.1)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (8.3.0)\n",
      "Requirement already satisfied: nest-asyncio in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (1.5.5)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: psutil in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (5.9.1)\n",
      "Requirement already satisfied: backcall in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.18.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pexpect>4.3 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (4.8.0)\n",
      "Requirement already satisfied: decorator in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (3.0.29)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (2.12.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (61.2.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (5.4.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from jinja2->altair>=3.2.0->streamlit->-r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (23.0.0)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (4.10.0)\n",
      "Requirement already satisfied: fastjsonschema in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (2.15.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (2.6.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (1.46.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from requests->transformers==4.0.0->-r requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from requests->transformers==4.0.0->-r requirements.txt (line 3)) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from requests->transformers==4.0.0->-r requirements.txt (line 3)) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from requests->transformers==4.0.0->-r requirements.txt (line 3)) (2022.5.18.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1.0->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (6.4.11)\n",
      "Requirement already satisfied: prometheus-client in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.14.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.15.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (21.3.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (6.5.0)\n",
      "Requirement already satisfied: defusedxml in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.7.1)\n",
      "Requirement already satisfied: tinycss2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (4.11.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: bleach in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.6.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: argon2-cffi-bindings in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from packaging->transformers==4.0.0->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from rich->streamlit->-r requirements.txt (line 5)) (0.9.1)\n",
      "Requirement already satisfied: joblib in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from sacremoses->transformers==4.0.0->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: asttokens in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (2.0.5)\n",
      "Requirement already satisfied: executing in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tzlocal->streamlit->-r requirements.txt (line 5)) (0.1.0.post0)\n",
      "Requirement already satisfied: backports.zoneinfo in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from tzlocal->streamlit->-r requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: tzdata in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from pytz-deprecation-shim->tzlocal->streamlit->-r requirements.txt (line 5)) (2022.1)\n",
      "Installing collected packages: torch, tokenizers, pyyaml, transformers, pytorch-lightning\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.1+cu110\n",
      "    Uninstalling torch-1.7.1+cu110:\n",
      "      Successfully uninstalled torch-1.7.1+cu110\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.3.3\n",
      "    Uninstalling transformers-4.3.3:\n",
      "      Successfully uninstalled transformers-4.3.3\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.2.1\n",
      "    Uninstalling pytorch-lightning-1.2.1:\n",
      "      Successfully uninstalled pytorch-lightning-1.2.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.8.2+cu110 requires torch==1.7.1, but you have torch 1.7.0 which is incompatible.\n",
      "torchaudio 0.7.2 requires torch==1.7.1, but you have torch 1.7.0 which is incompatible.\n",
      "kobart 0.5.1 requires pytorch-lightning==1.2.1, but you have pytorch-lightning 1.1.0 which is incompatible.\n",
      "kobart 0.5.1 requires torch==1.7.1, but you have torch 1.7.0 which is incompatible.\n",
      "kobart 0.5.1 requires transformers==4.3.3, but you have transformers 4.0.0 which is incompatible.\u001b[0m\n",
      "Successfully installed pytorch-lightning-1.1.0 pyyaml-5.4.1 tokenizers-0.9.4 torch-1.7.0 transformers-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3d4e6",
   "metadata": {},
   "source": [
    "# cuda버전과 torch버전 gpu에 맞게 설치 (A100 기준)\n",
    "https://pytorch.org/get-started/previous-versions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4037049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.7.1+cu110\n",
      "  Using cached https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp38-cp38-linux_x86_64.whl (1156.8 MB)\n",
      "Requirement already satisfied: torchvision==0.8.2+cu110 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (0.8.2+cu110)\n",
      "Requirement already satisfied: torchaudio==0.7.2 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (0.7.2)\n",
      "Requirement already satisfied: typing-extensions in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from torch==1.7.1+cu110) (4.2.0)\n",
      "Requirement already satisfied: numpy in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from torch==1.7.1+cu110) (1.22.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages (from torchvision==0.8.2+cu110) (9.1.1)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.0\n",
      "    Uninstalling torch-1.7.0:\n",
      "      Successfully uninstalled torch-1.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kobart 0.5.1 requires pytorch-lightning==1.2.1, but you have pytorch-lightning 1.1.0 which is incompatible.\n",
      "kobart 0.5.1 requires transformers==4.3.3, but you have transformers 4.0.0 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701be2e",
   "metadata": {},
   "source": [
    "# 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38517f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Namespace(accelerator='ddp', accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, automatic_optimization=None, batch_size=4, benchmark=False, check_val_every_n_epoch=1, checkpoint_callback=True, checkpoint_path=None, default_root_dir='logs', deterministic=False, distributed_backend=None, enable_pl_optimizer=True, fast_dev_run=False, flush_logs_every_n_steps=100, gpus=1, gradient_clip_val=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=3e-05, max_epochs=50, max_len=512, max_steps=None, min_epochs=1, min_steps=None, model_path=None, move_metrics_to_cpu=False, num_nodes=1, num_processes=1, num_sanity_val_steps=2, num_workers=5, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=1, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, sync_batchnorm=False, terminate_on_nan=False, test_file='data/test.csv', tpu_cores=<function _gpus_arg_default at 0x7f4c767e5940>, track_grad_norm=-1, train_file='data/train.csv', truncated_bptt_steps=None, val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n",
      "/home/dilab05/work_directory/신재광/NLP-pro/.cache/kobart_base_cased_ff4bda5738.zip[██████████████████████████████████████████████████]\n",
      "/home/dilab05/work_directory/신재광/NLP-pro/.cache/kobart_base_tokenizer_cased_cf74400bce.zip[██████████████████████████████████████████████████]\n",
      "using cached model. /home/dilab05/work_directory/신재광/NLP-pro/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "INFO:lightning:initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "INFO:root:number of workers 1, data length 200000\n",
      "INFO:root:num_train_steps : 2500000\n",
      "INFO:root:num_warmup_steps : 250000\n",
      "\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | BartForConditionalGeneration | 123 M \n",
      "-------------------------------------------------------\n",
      "123 M     Trainable params\n",
      "0         Non-trainable params\n",
      "123 M     Total params\n",
      "INFO:lightning:\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | BartForConditionalGeneration | 123 M \n",
      "-------------------------------------------------------\n",
      "123 M     Trainable params\n",
      "0         Non-trainable params\n",
      "123 M     Total params\n",
      "Epoch 0:   0%| | 43/56250 [00:04<1:45:11,  8.90it/s, loss=14.8, v_num=8, val_los^C\n",
      "/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Saving latest checkpoint...\n",
      "INFO:lightning:Saving latest checkpoint...\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 235, in <module>\n",
      "    trainer.fit(model, dm)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 470, in fit\n",
      "    results = self.accelerator_backend.train()\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/accelerators/ddp_accelerator.py\", line 143, in train\n",
      "    results = self.ddp_train(process_idx=self.task_idx, model=model)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/accelerators/ddp_accelerator.py\", line 298, in ddp_train\n",
      "    results = self.train_or_test()\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 65, in train_or_test\n",
      "    results = self.trainer.train()\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 552, in train\n",
      "    self.train_loop.on_train_end()\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\", line 191, in on_train_end\n",
      "    self.check_checkpoint_callback(should_save=True, is_last=True)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\", line 225, in check_checkpoint_callback\n",
      "    callback.on_validation_end(self.trainer, model)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 202, in on_validation_end\n",
      "    self.save_checkpoint(trainer, pl_module)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 235, in save_checkpoint\n",
      "    self._validate_monitor_key(trainer)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\", line 516, in _validate_monitor_key\n",
      "    raise MisconfigurationException(m)\n",
      "pytorch_lightning.utilities.exceptions.MisconfigurationException: ModelCheckpoint(monitor='val_loss') not found in the returned metrics: ['train_loss']. HINT: Did you call self.log('val_loss', tensor) in the LightningModule?\n"
     ]
    }
   ],
   "source": [
    " !python train.py  --gradient_clip_val 1.0 --max_epochs 50 --default_root_dir logs  --gpus 1 --accelerator ddp --batch_size 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d1df95",
   "metadata": {},
   "source": [
    "# 학습한 결과로 모델 binary 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a2a077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_model_binary.py:13: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\r\n",
      "  hparams = yaml.load(f)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"get_model_binary.py\", line 13, in <module>\r\n",
      "    hparams = yaml.load(f)\r\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/yaml/__init__.py\", line 114, in load\r\n",
      "    return loader.get_single_data()\r\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/yaml/constructor.py\", line 51, in get_single_data\r\n",
      "    return self.construct_document(node)\r\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/yaml/constructor.py\", line 60, in construct_document\r\n",
      "    for dummy in generator:\r\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/yaml/constructor.py\", line 413, in construct_yaml_map\r\n",
      "    value = self.construct_mapping(node)\r\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/yaml/constructor.py\", line 218, in construct_mapping\r\n",
      "    return super().construct_mapping(node, deep=deep)\r\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/yaml/constructor.py\", line 143, in construct_mapping\r\n",
      "    value = self.construct_object(value_node, deep=deep)\r\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/yaml/constructor.py\", line 102, in construct_object\r\n",
      "    data = constructor(self, tag_suffix, node)\r\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/yaml/constructor.py\", line 570, in construct_python_name\r\n",
      "    return self.find_python_name(suffix, node.start_mark)\r\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/yaml/constructor.py\", line 556, in find_python_name\r\n",
      "    raise ConstructorError(\"while constructing a Python object\", mark,\r\n",
      "yaml.constructor.ConstructorError: while constructing a Python object\r\n",
      "module 'pytorch_lightning.utilities.argparse' is not imported\r\n",
      "  in \"./logs/tb_logs/default/version_7/hparams.yaml\", line 56, column 12\r\n"
     ]
    }
   ],
   "source": [
    "!python get_model_binary.py --hparams ./logs/tb_logs/default/version_7/hparams.yaml  --model_binary ./logs/kobart_translation-model_chp/epoch=49-val_loss=0.875.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd0542",
   "metadata": {},
   "source": [
    "# binary 파일 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d81f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dilab05/work_directory/신재광/KoBART-translation/kobart_translation\n"
     ]
    }
   ],
   "source": [
    "%cd ./kobart_translation\n",
    "%mv config.json ../translation_binary\n",
    "%mv pytorch_model.bin ../translation_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113bc35",
   "metadata": {},
   "source": [
    "# infer.py 실행하기 위해서 밖에 폴더로 나가기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174b2464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dilab05/work_directory/신재광/KoBART-translation\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ea7559",
   "metadata": {},
   "source": [
    "# infer.py를 실행하여 내 로컬에서 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5bf39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.154.67:8502\u001b[0m\n",
      "\u001b[0m\n",
      "Some weights of the model checkpoint at ./translation_binary were not used when initializing BartForConditionalGeneration: ['lm_head.weight']\n",
      "- This IS expected if you are initializing BartForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 16:42:55.105 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 29, in <module>\n",
      "    if (output[:,i])==(output[:,i+1]):\n",
      "IndexError: index 16 is out of bounds for dimension 1 with size 16\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 16:45:39.362 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 29, in <module>\n",
      "    if(output[:,i] == output[:,i+1]):\n",
      "IndexError: index 16 is out of bounds for dimension 1 with size 16\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 16:48:57.915 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 28, in <module>\n",
      "    arr[a,b] = output.shape\n",
      "NameError: name 'arr' is not defined\n",
      "2022-06-13 16:50:29.742 Received event for non-watched file: /home/dilab05/work_directory/신재광/KoBART-translation/infer.py\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 16:50:35.389 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 29, in <module>\n",
      "    if(output[:,i] == output[:,i+1]):\n",
      "IndexError: index 16 is out of bounds for dimension 1 with size 16\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 16:52:27.255 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 30, in <module>\n",
      "    del output[:,i]\n",
      "TypeError: Tensor does not support deleting items\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 16:54:02.134 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 30, in <module>\n",
      "    output[:,i]=None\n",
      "TypeError: can't assign a NoneType to a torch.LongTensor\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 16:55:14.642 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 30, in <module>\n",
      "    del output[:,i]\n",
      "TypeError: Tensor does not support deleting items\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:14:40.259 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 30, in <module>\n",
      "    del npoutput[1,3]\n",
      "ValueError: cannot delete array elements\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:18:46.206 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 30, in <module>\n",
      "    numpy.delete(npoutput,1)\n",
      "NameError: name 'numpy' is not defined\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:24:41.604 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 32, in <module>\n",
      "    st.write(npoutput.type())\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'type'\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:24:55.892 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 32, in <module>\n",
      "    st.write(npoutput.type)\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'type'\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:30:34.120 Received event for non-watched file: /home/dilab05/work_directory/신재광/KoBART-translation/infer.py\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:30:40.464 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 32, in <module>\n",
      "    if npoutput(1,i)==npoutput(1,i+1):\n",
      "TypeError: 'numpy.ndarray' object is not callable\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:31:11.469 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 32, in <module>\n",
      "    if (npoutput(1,i))==(npoutput(1,i+1)):\n",
      "TypeError: 'numpy.ndarray' object is not callable\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:32:33.215 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 32, in <module>\n",
      "    c=npoutput(1,i)\n",
      "TypeError: 'numpy.ndarray' object is not callable\n",
      "2022-06-13 17:34:09.274 Received event for non-watched file: /home/dilab05/work_directory/신재광/KoBART-translation/infer.py\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:36:51.684 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 34, in <module>\n",
      "    a,b=npoutput,shape\n",
      "NameError: name 'shape' is not defined\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:41:01.636 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 35, in <module>\n",
      "    output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 3109, in decode\n",
      "    return self._decode(\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\", line 491, in _decode\n",
      "    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)\n",
      "TypeError: 'float' object cannot be interpreted as an integer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:47:43.683 Received event for non-watched file: /home/dilab05/work_directory/신재광/KoBART-translation/infer.py\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:49:52.612 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 31, in <module>\n",
      "    if output[:,i]==output[:,i+1]:\n",
      "IndexError: index 14 is out of bounds for dimension 1 with size 14\n",
      "2022-06-13 17:54:38.556 Received event for non-watched file: /home/dilab05/work_directory/신재광/KoBART-translation/infer.py\n",
      "2022-06-13 17:56:51.357 Received event for non-watched file: /home/dilab05/work_directory/신재광/KoBART-translation/infer.py\n",
      "2022-06-13 17:57:19.618 Received event for non-watched file: /home/dilab05/work_directory/신재광/KoBART-translation/infer.py\n",
      "2022-06-13 17:57:29.233 Received event for non-watched file: /home/dilab05/work_directory/신재광/KoBART-translation/infer.py\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:57:34.807 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 31, in <module>\n",
      "    if output[:,i]==output[:,i+1]:\n",
      "IndexError: index 14 is out of bounds for dimension 1 with size 14\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 17:58:49.501 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 31, in <module>\n",
      "    if output[:,i]==output[:,i+1]:\n",
      "IndexError: index 14 is out of bounds for dimension 1 with size 14\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 18:12:31.746 Received event for non-watched file: /home/dilab05/work_directory/신재광/KoBART-translation/infer.py\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 18:12:38.404 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 31, in <module>\n",
      "    if output[:,i]==output[:,i+1]:\n",
      "IndexError: index 14 is out of bounds for dimension 1 with size 14\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 18:13:54.301 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 31, in <module>\n",
      "    if output[:,i]==output[:,i+1]:\n",
      "IndexError: index 14 is out of bounds for dimension 1 with size 14\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 18:15:17.590 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 31, in <module>\n",
      "    if output[:,i]==output[:,i+1]:\n",
      "IndexError: index 14 is out of bounds for dimension 1 with size 14\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 18:15:33.147 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 31, in <module>\n",
      "    if output[:,i]==output[:,i+1]:\n",
      "IndexError: index 14 is out of bounds for dimension 1 with size 14\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 18:16:23.270 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 31, in <module>\n",
      "    if output[:,i]==output[:,i+1]:\n",
      "IndexError: index 14 is out of bounds for dimension 1 with size 14\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 18:16:37.595 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 31, in <module>\n",
      "    if output[:,i]==output[:,i+1]:\n",
      "IndexError: index 14 is out of bounds for dimension 1 with size 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 18:19:13.360 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 32, in <module>\n",
      "    output2 = torch.cat((output2[:,:i], output2[:,i+1:]), axis = 1)\n",
      "NameError: name 'output2' is not defined\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 18:52:01.106 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 30, in <module>\n",
      "    while i<b-1:\n",
      "NameError: name 'i' is not defined\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "infer.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "2022-06-13 19:02:27.335 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 29, in <module>\n",
      "    st.write(output2[:,:3])\n",
      "IndexError: too many indices for tensor of dimension 1\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "infer.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output2 = torch.unique(torch.tensor(output, dtype=torch.long))\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "infer.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output2 = torch.unique(torch.tensor(output, dtype=torch.long))\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "infer.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output2 = torch.unique(torch.tensor(output, dtype=torch.long))\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "infer.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output2 = torch.unique(torch.tensor(output, dtype=torch.long))\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "infer.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output2 = torch.unique(torch.tensor(output, dtype=torch.long))\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 19:08:07.748 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 29, in <module>\n",
      "    st.write(output[:,:3])\n",
      "IndexError: too many indices for tensor of dimension 1\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "2022-06-13 19:14:17.592 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"infer.py\", line 28, in <module>\n",
      "    output2 = torch.unique_consecutive(output, dim=2)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/torch/_jit_internal.py\", line 267, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/torch/_jit_internal.py\", line 267, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/torch/functional.py\", line 832, in _consecutive_return_output\n",
      "    output, _, _ = _unique_consecutive_impl(input, return_inverse, return_counts, dim)\n",
      "  File \"/home/dilab05/anaconda3/envs/tf-2.7.0/lib/python3.8/site-packages/torch/functional.py\", line 744, in _unique_consecutive_impl\n",
      "    output, inverse_indices, counts = _VF.unique_consecutive(  # type: ignore\n",
      "IndexError: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "using cached model. /home/dilab05/work_directory/신재광/KoBART-translation/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run infer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba59919",
   "metadata": {},
   "source": [
    "# 결과 및 응용\n",
    "\n",
    "* 결과로는 짧은 문장은 번역할 때 말을 더듬는 것 처럼 번역을 하였는데 (ex. I I I I want go to home) 이 문제를 분석하였고, 결과로는 tokenizer 과정에서 '나'+'ㄴ'+'ㅡ'+'ㄴ'으로 나누고 이 4가지를 모두 I 로 번역을 한 것 같아서 연속적으로 반복되는 구간을 한개로 줄였다.\n",
    "\n",
    "* 가상환경 설정할 떄 A100에서 구동을 하였는데, 각자의 컴퓨터 환경이 같지 않아서 cuda 버젼을 맞는 것을 찾아봐야 할 것 같다.\n",
    "* dataset은 직접 전처리를 하여서 넣었다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358f457d",
   "metadata": {},
   "source": [
    "# 참고 문헌\n",
    "\n",
    "https://github.com/seujung/KoBART-translation 모델\n",
    "https://aihub.or.kr/aidata/7974 데이터셋"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KoBart",
   "language": "python",
   "name": "kobart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
